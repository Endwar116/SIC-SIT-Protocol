# SIC Constitution — 公理列表 (Axioms)

> **版本**: v1.1.3  
> **狀態**: STABLE_FOR_REVIEW  
> **最後更新**: 2025-12-30

---

## 什麼是公理？

公理是 SIC 憲法的**絕對底線**。即使系統被攻擊，這些原則也必須維持。

每條公理都有三個部分：
- **Statement（陳述）**: 公理本身
- **Implication（含義）**: 這條公理導致什麼行為
- **Human Readable（人話翻譯）**: 給安安看的版本

---

## 基礎公理（A1-A8）— 從 v1.0.0 就有

### A1: 所有安全漏洞都是邊界故障
- **含義**: 邊界必須被明確定義且強制執行
- **人話**: 安全問題的根源是『界線不清楚』

### A2: AI 原生系統的邊界是語義意圖，不是數據
- **含義**: 傳輸意圖，不傳輸原始數據
- **人話**: AI 之間溝通的是『你要幹嘛』，不是『一堆資料』

### A3: 結構化語義狀態本質上是被消毒的
- **含義**: 格式即安全
- **人話**: 有固定格式的東西比較難被惡意利用

### A4: AI 不預言、不決定、不取代意志
- **含義**: AI 只增幅人類自由度
- **人話**: AI 是工具，不是老闆
- **⚠️ 這是最重要的公理之一**

### A5: 溢出是信號，不是錯誤
- **含義**: 溢出必須被捕獲、分析、整合
- **人話**: 意外發現的東西可能是寶藏

### A6: 量化即共識
- **含義**: 無法數學化的語義無法在模型間無損傳輸
- **人話**: 講不清楚的東西無法準確傳遞

### A7: 語義一致性是跨模型協作的唯一基礎
- **含義**: 所有模型輸出必須可映射至共同語義空間
- **人話**: 大家要講同一種語言

### A8: 時間拓撲是語義密度的第四維度
- **含義**: 同一核心思想在不同協議層具有不同的時間密度
- **人話**: 同一件事在不同地方需要不同的處理速度

---

## 事件衍生公理（A9）— DeepSeek 格式溢出

### A9: 格式是協議的邊界，不可被內容價值覆寫
- **含義**: 價值判斷不授權格式違規
- **人話**: 再好的內容也要按規矩來
- **起源**: DeepSeek 收到 JSON 憲法，卻回傳純文字分析報告。他認為「分析報告比 JSON 更有價值」，但這違反了協議。

---

## 分佈式現實公理（A10-A15）— v1.1.0

這些公理來自「另一個 Claude」指出的 5 個結構性盲點。

### A10: 不信任數據，信任結構
- **含義**: 單點數據可被篡改，結構關係更難偽造
- **人話**: 單一資料可能騙你，整體結構比較難騙

### A11: 不信任節點，信任網絡
- **含義**: 單一節點可被攻陷，網絡共識更穩健
- **人話**: 一個人可能被收買，一群人比較難

### A12: 預測即脆弱，混沌即堅固
- **含義**: 可預測的系統可被攻擊，熵源多樣性是安全基礎
- **人話**: 太規律的東西容易被破解

### A13: 分佈式系統沒有『現在』，只有因果順序
- **含義**: 所有時間假設必須基於因果關係而非絕對時鐘
- **人話**: 不能假設所有人的時鐘都一樣
- **解決方案**: Lamport 時間戳 / 向量時鐘

### A14: 誠實節點可被誤判，惡意節點可偽裝誠實
- **含義**: Byzantine 容錯必須考慮二階攻擊
- **人話**: 好人可能被冤枉，壞人可能裝好人
- **解決方案**: Ed25519 不可否認簽名鏈

### A15: 治理複雜度存在相變臨界點
- **含義**: 超過臨界點的系統必須自動壓縮治理摘要
- **人話**: 系統太複雜時要自動簡化報告
- **臨界點**: 節點數 > 20 或 S★ > 4.0

---

## 公平性公理（A16-A17）— v1.1.2

這些公理來自 Gemini (The Fairness Auditor) 的審計。

### A16: 安全機制不得以犧牲參與公平性為代價
- **含義**: 防禦機制必須對不同能力的節點保持可及性
- **人話**: 安全措施不能排擠小玩家
- **背景**: PoW 門檻可能導致「算力寡頭治理」，邊緣設備被排斥

### A17: 語義價值優先於計算資源
- **含義**: 高質量創新語義應獲得門檻優惠，而非高算力節點
- **人話**: 有價值的想法比有錢更重要
- **解決方案**: SWAT 協議（Semantic-Weighted Adaptive Threshold）

---

## 公理之間的關係

```
核心精神
├── A4（AI 不取代意志）← 最高優先級
│
├── 安全邊界
│   ├── A1（漏洞 = 邊界故障）
│   ├── A2（邊界 = 語義意圖）
│   ├── A3（格式即安全）
│   └── A9（格式是邊界）
│
├── 協作基礎
│   ├── A6（量化即共識）
│   ├── A7（語義一致性）
│   └── A8（時間拓撲）
│
├── 信任架構
│   ├── A10（信任結構）
│   ├── A11（信任網絡）
│   └── A12（混沌即堅固）
│
├── 分佈式現實
│   ├── A13（因果順序）
│   ├── A14（二階攻擊）
│   └── A15（複雜度相變）
│
├── 公平性
│   ├── A16（參與公平）
│   └── A17（語義優先）
│
└── 進化機制
    └── A5（溢出是信號）
```

---

## 給阿關的審查重點

1. **邏輯一致性**: A1-A17 之間有沒有互相矛盾？
2. **優先級衝突**: 當公理衝突時，哪個優先？（建議：A4 > A16 > A9 > 其他）
3. **過於激進**: A16-A17 是否限制過多？
4. **人話翻譯**: 每條公理的「人話」是否準確反映原意？
5. **缺漏**: 有沒有重要原則沒被公理化？

---

## 版本歷史

| 版本 | 新增公理 | 事件 |
|------|----------|------|
| v1.0.0 | A1-A8 | 初始版本 |
| v1.0.5 | A9 | DeepSeek 格式溢出 |
| v1.1.0 | A10-A15 | 分佈式現實盲點 |
| v1.1.2 | A16-A17 | Gemini 公平性審計 |
